# SPDX-License-Identifier: Apache-2.0

# Default values for a production hiero block-node-server StatefulSet
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

image:
  repository: ghcr.io/hiero-ledger/hiero-block-node
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: ""

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}

podSecurityContext: {}
# fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
# runAsUser: 1000

service:
  type: ClusterIP
  port: 40840

ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources:
  requests:
    cpu: "4"
    memory: "12Gi"
  limits:
    cpu: "4"
    memory: "15Gi"

nodeSelector: {}

tolerations: []

affinity: {}

blockNode:
  # init container verbatim
  initContainers:
    - name: init-storage-dirs
      image: busybox
      command:
        - sh
        - -c
        - |
          mkdir -p /live-pvc/live-data && \
          chown 2000:2000 /live-pvc/live-data && \
          chmod 700 /live-pvc/live-data && \
          mkdir -p /archive-pvc/archive-data && \
          chown 2000:2000 /archive-pvc/archive-data && \
          chmod 700 /archive-pvc/archive-data

     # download plugins and put them in plugins
      volumeMounts:
        - name: live-storage
          mountPath: /live-pvc
        - name: archive-storage
          mountPath: /archive-pvc
        - name: plugins
        mountPath: /plugins #application path
  # if blank will use same as AppVersion of chart.
  version: ""
  config:
    # Add any additional env configuration here
    # key: value
    JAVA_TOOL_OPTIONS: "-Djava.util.logging.config.file=/opt/hiero/block-node/logs/config/logging.properties"
    JAVA_OPTS: '-Xms16G -Xmx16G -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath="/tmp/dump.hprof"'
    # PRODUCER_TYPE: "NO_OP"
    # PERSISTENCE_STORAGE_TYPE: "NO_OP"
    # VERIFICATION_TYPE: "NO_OP"
    # MESSAGING_BLOCK_ITEM_QUEUE_SIZE: "512"
    # MESSAGING_BLOCK_NOTIFICATION_QUEUE_SIZE: "16"
    PROMETHEUS_ENDPOINT_ENABLED: true
    PROMETHEUS_ENDPOINT_PORT_NUMBER: "16007"
    SERVER_PORT: "40840"
    # The path to the block-node-sources.json file must match the path property in the backfill.sources.path
    # if using the backfill sources created with this helm chart
    # BACKFILL_BLOCK_NODE_SOURCES_PATH: "/opt/hiero/block-node/backfill/block-node-sources.json"
    # BACKFILL_FETCH_BATCH_SIZE: "25"
  persistence:
    archive:
      # name of the volume within the statefulset
      volumeName: "archive-storage"
      # Name of the subPath in the volume to mount to mountPath in the container
      subPath: "archive-data"
      # should match PERSISTENCE_STORAGE_ARCHIVE_ROOT_PATH, leave as is for default.
      mountPath: "/opt/hiero/block-node/data/historic"
      size: 800Gi
      # Optionally add a storage class name if needed
      # storageClass: "your-storage-class"
      # Optionally specify an existing PVC name instead of creating via volumeClaimTemplate
      # existingClaim: "my-archive-pvc"
    logging:
      # name of the volume within the statefulset
      volumeName: "logging-storage"
      mountPath: "/opt/hiero/block-node/logs"
      size: 2Gi
      # Optionally add a storage class name if needed
      # storageClass: "your-storage-class"
      # Optionally specify an existing PVC name instead of creating via volumeClaimTemplate
      # existingClaim: "my-logging-pvc"
    live:
      # name of the volume within the statefulset
      volumeName: "live-storage"
      # Name of the subPath in the volume to mount to mountPath in the container
      subPath: "live-data"
      # should match PERSISTENCE_STORAGE_LIVE_ROOT_PATH, leave as is for default.
      mountPath: "/opt/hiero/block-node/data/live"
      size: 20Gi

      plugins:
        # name of the volume within the statefulset
        volumeName: "plugins"
        mountPath: "/plugins"
        size: 5Gi
      # Optionally add a storage class name if needed
      # storageClass: "your-storage-class"
      # Optionally specify an existing PVC name instead of creating via volumeClaimTemplate
      # existingClaim: "my-live-pvc"
  # For secrets, is recommended to use a secretRef to an existing secret on the cluster.
  # secretRef: secret-name-reference
  # not recommended to use this, but for testing purposes you can use the following collection for secrets auto-creation
  # secret:
  #   EXAMPLE_SECRET: "FAKE EXAMPLE VALUE SECRET"
  health:
    readiness:
      endpoint: "/healthz/readyz"
    liveness:
      endpoint: "/healthz/livez"
    metrics:
      port: 16007
  logs:
    # Available Levels are (from most verbose to least verbose):
    # ALL FINEST FINER FINE CONFIG INFO WARNING SEVERE OFF
    level: "INFO"
    configMountPath: "/opt/hiero/block-node/logs/config"
    loggingProperties:
      # logs for Block Node components FINEST temporarily while testing is ongoing
      org.hiero.block.level: "FINEST"
      io.helidon.level: "INFO"
      io.helidon.webserver.level: "INFO"
      io.helidon.webserver.access.level: "INFO"
      io.helidon.config.level: "SEVERE"
      io.helidon.security.level: "INFO"
      io.helidon.common.level: "INFO"
      handlers: "java.util.logging.ConsoleHandler, java.util.logging.FileHandler"
      java.util.logging.ConsoleHandler.level: "FINEST"
      java.util.logging.ConsoleHandler.formatter: "java.util.logging.SimpleFormatter"
      java.util.logging.FileHandler.pattern: "/opt/hiero/block-node/logs/blocknode-%g.log"
      java.util.logging.FileHandler.append: "true"
      java.util.logging.FileHandler.limit: "5000000"
      java.util.logging.FileHandler.count: "5"
      java.util.logging.FileHandler.level: "FINEST"
      java.util.logging.FileHandler.formatter: "java.util.logging.SimpleFormatter"
      # Override the chatty HTTP server internals
      com.sun.net.httpserver.level: "WARNING"
      com.sun.net.httpserver.ServerImpl.level: "WARNING"
      com.sun.net.httpserver.ExchangeImpl.level: "WARNING"
      ################################################################################
      # SimpleFormatter single-line format configuration
      ################################################################################
      # The format syntax uses java.util.Formatter.
      # The parameters are:
      #   %1$ - date/time (java.util.Date)
      #   %2$ - source (usually class and method)
      #   %3$ - logger?s name
      #   %4$ - log level
      #   %5$ - log message
      #   %6$ - throwable trace
      java.util.logging.SimpleFormatter.format: "%TF %<TT.%<TL%<Tz %4$-7s [%2$s] %5$s%6$s%n"
  backfill:
    # The path to the block-node-sources.json file must match the path property in blockNode.config.BACKFILL_BLOCK_NODE_SOURCES_PATH
    path: "/opt/hiero/block-node/backfill"
    filename: "block-node-sources.json"
    # uncomment or override the sources to enable backfilling
    # see backfill.yaml override for an explicit example.
    # sources:
    #   - address: "source-block-node-helm-chart.default.svc.cluster.local"
    #     port: 40840
    #     priority: 1

kubepromstack:
  enabled: false
  prometheus:
    prometheusSpec:
      retention: 90d
      storageSpec:
        volumeClaimTemplate:
          spec:
            accessModes: ["ReadWriteOnce"]
            resources:
              requests:
                storage: 20Gi
  prometheusOperator:
    namespaces:
      releaseNamespace: true
  grafana:
    replicas: 1
    enabled: true
    defaultDashboardsEnabled: false
    adminPassword: "admin"
    datasources:
      datasources.yaml: {}
    sidecar:
      dashboards:
        enabled: true
        label: grafana_dashboard
        provider:
          allowUiUpdates: true
      datasources:
        enabled: true
        label: grafana_datasource
    persistence:
      enabled: true
      type: pvc
      size: 10Gi
  nodeExporter:
    enabled: true

loki:
  enabled: false
  isDefault: true
  url: http://{{(include "loki.serviceName" .)}}:{{ .Values.loki.service.port }}
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  livenessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  datasource:
    jsonData: "{}"
    uid: ""
  persistence:
    enabled: true
    size: 20Gi
    # storageClassName: ""

promtail:
  enabled: false
  config:
    logLevel: info
    serverPort: 3101
    clients:
      - url: http://{{ .Release.Name }}-loki:3100/loki/api/v1/push
    snippets:
      pipelineStages:
        - docker:
            label_fields:
              stream: stream
        - multiline:
            # A regex that identifies the start of a new log entry
            firstline: '^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}'
            # Maximum wait time for more lines before sending the collected log upstream
            max_wait_time: 3s
            separator: ''
        - replace:
            expression: '(\n){2,}'
            replace: ''
